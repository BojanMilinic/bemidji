{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have sqlalchemy-access installed for uploading back into the database\n",
    "\n",
    "Only needs to be done once! \n",
    "\n",
    "You can't be connected to VPN due to encryption issues. Install using Anaconda prompt when disconnected from VPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only needed if you want to reupload to Microsoft Access database\n",
    "#pip install sqlalchemy-access"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for creating dataframe\n",
    "import pyodbc #working with ODBC databases\n",
    "import numpy as np # for locating values in dataframes\n",
    "from datetime import datetime # for obtaining today's date\n",
    "import os #for working with directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional- set dfs to show actual numbers rather than scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\\0083\\analysis\\DataCompilation\\DataCompilationPy\\create_site_info_files\n"
     ]
    }
   ],
   "source": [
    "# my default directory is c:\\Users\\bmilinic\\OneDrive - DOI\\Documents\\Python\\bemidji\n",
    "defaultdirectory = os.getcwd()\n",
    "print(defaultdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the shared drive which holds the databases and files \n",
    "os.chdir('P:/0083/analysis/DataCompilation/DataCompilationPy/create_site_info_files')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from GWSI Python output \n",
    "dfbmj3 = pd.read_csv(r'data_inputs/gwsi_old/bmj3_fromPy.csv')\n",
    "dfrmk = pd.read_csv(r'data_inputs/gwsi_old/bmj_rmk_fromPy.csv')\n",
    "# from Python outout aquarius and MLR \n",
    "dfaq = pd.read_csv(r'data_inputs/aquarius/Referencepoints_updatedMP_fromPy.csv') \n",
    "dfmlr = pd.read_csv(r'data_inputs/MLR/MLR_fromPy.csv')\n",
    "\n",
    "# Import data from Microsoft Access Using PYODBC\n",
    "Gfe_db = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=P:\\0083\\analysis\\DataCompilation\\DataCompilationPy\\local_access_db\\BemidjiMasterSiteData_fe.accdb;')\n",
    "c_fe = Gfe_db.cursor()\n",
    "# tables\n",
    "tblSites = pd.read_sql('select * from tblSites', Gfe_db)\n",
    "tblWells = pd.read_sql('select * from tblWells', Gfe_db)\n",
    "tblCores = pd.read_sql('select * from tblCores', Gfe_db)\n",
    "tblOE = pd.read_sql('select * from tblOtherEquipment', Gfe_db)\n",
    "# cd tables\n",
    "tblcd_LocalUseCode = pd.read_sql(\"select * from tblcd_LocalUseCode\", Gfe_db)  \n",
    "tblcd_CasingMaterial = pd.read_sql(\"select * from tblcd_CasingMaterial\", Gfe_db)   \n",
    "tblcd_ScreenMaterial = pd.read_sql(\"select * from tblcd_ScreenMaterial\", Gfe_db)   \n",
    "tblcd_OpeningType = pd.read_sql(\"select * from tblcd_OpeningType\", Gfe_db)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tbleSites (local access) with GWSI (retrieved) to update the USGS station names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1729, 123)\n",
      "(1731, 216)\n",
      "(1741, 248)\n",
      "(2474, 289)\n",
      "(2474, 331)\n",
      "(2474, 347)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmilinic\\AppData\\Local\\Temp\\1\\ipykernel_27076\\1114989423.py:15: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Wellcon_SiteRecordID_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  dfcomplete = pd.merge(dfcomplete, tblCores, on='LocalSiteName', how='left')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2474, 354)\n"
     ]
    }
   ],
   "source": [
    "# merge tblSites and dfbmj3: match up datatypes of the columns that the dfs will be merged on\n",
    "tblSites2 = tblSites\n",
    "tblSites2['USGS_siteno'] = tblSites2['USGS_siteno'].fillna(0).astype('int64')\n",
    "dfcomplete = pd.merge(tblSites2, dfbmj3, left_on='USGS_siteno', right_on='GWSI_USGS_siteno', how='left')\n",
    "# turn zeros back into NaN\n",
    "dfcomplete['USGS_siteno'].replace(0, np.nan, inplace=True) \n",
    "print(dfcomplete.shape)\n",
    "# Merge tbl wells\n",
    "dfcomplete = pd.merge(dfcomplete, tblWells, on='LocalSiteName', how='left')\n",
    "print(dfcomplete.shape)\n",
    "# Merge tblOE\n",
    "dfcomplete = pd.merge(dfcomplete, tblOE, on='LocalSiteName', how='left')\n",
    "print(dfcomplete.shape)\n",
    "# Merge tblCores\n",
    "dfcomplete = pd.merge(dfcomplete, tblCores, on='LocalSiteName', how='left')\n",
    "print(dfcomplete.shape)\n",
    "# Merge dfmlr\n",
    "dfcomplete = pd.merge(dfcomplete, dfmlr, left_on='USGS_siteno', right_on='site_no', how='left')\n",
    "print(dfcomplete.shape)\n",
    "# Merge dfaq\n",
    "dfcomplete = pd.merge(dfcomplete, dfaq, left_on='USGS_siteno', right_on='site', how='left')\n",
    "print(dfcomplete.shape)\n",
    "# Local Use Codes\n",
    "dfcomplete = pd.merge(dfcomplete, tblcd_LocalUseCode[['LocalUseCode','Comments_UseCode']], how='left') #if you leave out the \"how\" (like in the original) then # of rows plummits\n",
    "dfcomplete = pd.merge(dfcomplete, tblcd_OpeningType[[\"TypeOfOpenInterval\", \"comments_OpeningType\"]], left_on='GWSI_TypeOfOpenInterval', right_on='TypeOfOpenInterval', how='left')\n",
    "dfcomplete = pd.merge(dfcomplete, tblcd_CasingMaterial[[\"CasingMaterial\", \"Comments_CasingMaterial\"]], left_on='GWSI_CasingMaterial', right_on='CasingMaterial', how='left')\n",
    "dfcomplete = pd.merge(dfcomplete, tblcd_ScreenMaterial[[\"ScreenMaterial\", \"Comments_ScreenMaterial\"]], left_on='GWSI_ScreenMaterialType', right_on='ScreenMaterial', how='left')\n",
    "print(dfcomplete.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate additional columns for GWSI\n",
    "dfcomplete['GWSI_MeasuringPointElevation_ftASL_NAVD88'] = dfcomplete['GWSI_LandSurfaceAltitude_ftASL_NAVD88'] + dfcomplete['GWSI_MP_height_ft']\n",
    "dfcomplete['MeasuringPointElevation_mASL_NAVD88'] = dfcomplete['GWSI_MeasuringPointElevation_ftASL_NAVD88'].mul(0.3048).round(3) #renamed for Wells\n",
    "\n",
    "dfcomplete['GWSI_MeasuringPointHeight_m'] = dfcomplete['GWSI_MP_height_ft'].mul(0.3048).round(3)\n",
    "\n",
    "dfcomplete['LandSurfaceAltitude_mASL_NAVD88'] = dfcomplete['GWSI_LandSurfaceAltitude_ftASL_NAVD88'].mul(0.3048).round(3) #renamed for Wells\n",
    "\n",
    "dfcomplete['GWSI_TopOfScreenElevation_ftASL_NAVD88'] = dfcomplete['GWSI_LandSurfaceAltitude_ftASL_NAVD88'] - dfcomplete['GWSI_TopOfScreenDepth_ftBLS']\n",
    "dfcomplete['TopOfScreenElevation_mASL_NAVD88'] = dfcomplete['GWSI_TopOfScreenElevation_ftASL_NAVD88'].mul(0.3048).round(3)\n",
    "\n",
    "dfcomplete['GWSI_BottomOfScreenElevation_ftASL_NAVD88'] = dfcomplete['GWSI_LandSurfaceAltitude_ftASL_NAVD88'] - dfcomplete['GWSI_BottomOfScreenDepth_ftBLS']\n",
    "dfcomplete['BottomOfScreenElevation_mASL_NAVD88'] = dfcomplete['GWSI_BottomOfScreenElevation_ftASL_NAVD88'].mul(0.3048).round(3)\n",
    "\n",
    "dfcomplete['GWSI_MidOfScreenElevation_mASL_NAVD88'] = dfcomplete['TopOfScreenElevation_mASL_NAVD88'] + dfcomplete['BottomOfScreenElevation_mASL_NAVD88']\n",
    "dfcomplete['MidOfScreenElevation_mASL_NAVD88'] = dfcomplete['GWSI_MidOfScreenElevation_mASL_NAVD88'].div(2).round(3)\n",
    "\n",
    "dfcomplete['TotalWellDepth_mBLS'] = dfcomplete['GWSI_TotalWellDepth_ftBLS'].mul(0.3048).round(3) #renamed for Wells\n",
    "\n",
    "dfcomplete['DiameterOfDrillHole_cm'] = dfcomplete['GWSI_DiameterOfDrillHole_inches'].mul(2.54).round(1) #renamed for Wells\n",
    "\n",
    "dfcomplete['WellCasingInnerDiameter_cm'] = dfcomplete['GWSI_WellCasingInnerDiameter_inches'].mul(2.54).round(1) #renamed for Wells\n",
    "\n",
    "dfcomplete['WidthOfOpeningsInOpenInterval_cm'] = dfcomplete['GWSI_WidthOfOpeningsInOpenInterval_inches'].mul(2.54).round(3) #renamed for Wells\n",
    "\n",
    "dfcomplete['GWSI_ScreenLength_ft'] = dfcomplete['GWSI_BottomOfScreenDepth_ftBLS'] - dfcomplete['GWSI_TopOfScreenDepth_ftBLS']\n",
    "dfcomplete['ScreenLength_m'] = dfcomplete['GWSI_ScreenLength_ft'].mul(.3048).round(3) #renamed for Wells\n",
    "\n",
    "dfcomplete['well_MP_height_m'] = dfcomplete['GWSI_MP_height_ft'].mul(.3048).round(3) #renamed for Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indicator columns in tblSites for which sites exist in each of site type tables (wells, cores, other equipment)\n",
    "tblSites2['WellSite'] = np.where(tblSites2['LocalSiteName'].isin(tblWells['LocalSiteName']), 1, 0) # inserts 1 if true and 0 if false\n",
    "tblSites2['CoreSite'] = np.where(tblSites2['LocalSiteName'].isin(tblCores['LocalSiteName']), 1, 0)\n",
    "tblSites2['OtherEquipmentSite'] = np.where(tblSites2['LocalSiteName'].isin(tblOE['LocalSiteName']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615, 94)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tblWells.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcomplete.loc[dfcomplete['LocalSiteName'] == '518G-06'].to_csv('deletemeplease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408     17\n",
       "1605     16\n",
       "1305     16\n",
       "1308     15\n",
       "1902     15\n",
       "         ..\n",
       "9318      1\n",
       "9319      1\n",
       "9320A     1\n",
       "9320B     1\n",
       "1603      1\n",
       "Name: LocalSiteName, Length: 736, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tblCores['LocalSiteName'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518G-06     2\n",
       "9103G-05    2\n",
       "15-N6       1\n",
       "9109        1\n",
       "9108        1\n",
       "           ..\n",
       "1112        1\n",
       "1111        1\n",
       "1110        1\n",
       "1109        1\n",
       "1706        1\n",
       "Name: LocalSiteName, Length: 1729, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcomplete['LocalSiteName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "boolean = dfcomplete.duplicated(subset=['LocalSiteName']).any()\n",
    "print(boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcomplete[['Wellcon_SiteRecordID_x','Wellcon_SiteRecordID_y']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          15-N6\n",
       "1          15-N7\n",
       "2          15-N8\n",
       "3          15-N9\n",
       "4         15-N10\n",
       "          ...   \n",
       "1736        1713\n",
       "1737    1711G-01\n",
       "1738      WT1712\n",
       "1739        1704\n",
       "1740        1706\n",
       "Name: LocalSiteName, Length: 1741, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcomplete.LocalSiteName"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all the rest of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17884b3f",
   "metadata": {},
   "source": [
    "# Import data from Microsoft Access Using PYODBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to databases\n",
    "Gbe_db = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=P:\\0083\\analysis\\DataCompilation\\DataCompilationPy\\local_access_db\\BemidjiMasterSiteData_be.accdb;')\n",
    "Gfe_db = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=P:\\0083\\analysis\\DataCompilation\\DataCompilationPy\\local_access_db\\BemidjiMasterSiteData_fe.accdb;')\n",
    "# create cursor instances for copying/editing databases (not needed if only downloading data)\n",
    "c_be = Gbe_db.cursor()\n",
    "c_fe = Gfe_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tblSites = pd.read_sql('select * from tblSites', Gfe_db)\n",
    "tblWells = pd.read_sql('select * from tblWells', Gfe_db)\n",
    "tblCores = pd.read_sql('select * from tblCores', Gfe_db)\n",
    "tblOE = pd.read_sql('select * from tblOtherEquipment', Gfe_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tblcd_LocalUseCode = pd.read_sql(\"select * from tblcd_LocalUseCode\", Gbe_db)  \n",
    "tblcd_CasingMaterial = pd.read_sql(\"select * from tblcd_CasingMaterial\", Gbe_db)   \n",
    "tblcd_ScreenMaterial = pd.read_sql(\"select * from tblcd_ScreenMaterial\", Gbe_db)   \n",
    "tblcd_OpeningType = pd.read_sql(\"select * from tblcd_OpeningType\", Gbe_db)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dfbmj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfbmj3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bmilinic\\OneDrive - DOI\\Documents\\Python\\bemidji\\02_data_convergence_automate.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bmilinic/OneDrive%20-%20DOI/Documents/Python/bemidji/02_data_convergence_automate.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# calculate additional columns\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bmilinic/OneDrive%20-%20DOI/Documents/Python/bemidji/02_data_convergence_automate.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dfbmj3[\u001b[39m'\u001b[39m\u001b[39mGWSI_MeasuringPointElevation_ftASL_NAVD88\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dfbmj3[\u001b[39m'\u001b[39m\u001b[39mGWSI_LandSurfaceAltitude_ftASL_NAVD88\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m dfbmj3[\u001b[39m'\u001b[39m\u001b[39mGWSI_MP_height_ft\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bmilinic/OneDrive%20-%20DOI/Documents/Python/bemidji/02_data_convergence_automate.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dfbmj3[\u001b[39m'\u001b[39m\u001b[39mMeasuringPointElevation_mASL_NAVD88\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dfbmj3[\u001b[39m'\u001b[39m\u001b[39mGWSI_MeasuringPointElevation_ftASL_NAVD88\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmul(\u001b[39m0.3048\u001b[39m)\u001b[39m.\u001b[39mround(\u001b[39m3\u001b[39m) \u001b[39m#renamed for Wells\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bmilinic/OneDrive%20-%20DOI/Documents/Python/bemidji/02_data_convergence_automate.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m dfbmj3[\u001b[39m'\u001b[39m\u001b[39mGWSI_MeasuringPointHeight_m\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dfbmj3[\u001b[39m'\u001b[39m\u001b[39mGWSI_MP_height_ft\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmul(\u001b[39m0.3048\u001b[39m)\u001b[39m.\u001b[39mround(\u001b[39m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfbmj3' is not defined"
     ]
    }
   ],
   "source": [
    "# calculate additional columns\n",
    "dfbmj3['GWSI_MeasuringPointElevation_ftASL_NAVD88'] = dfbmj3['GWSI_LandSurfaceAltitude_ftASL_NAVD88'] + dfbmj3['GWSI_MP_height_ft']\n",
    "dfbmj3['MeasuringPointElevation_mASL_NAVD88'] = dfbmj3['GWSI_MeasuringPointElevation_ftASL_NAVD88'].mul(0.3048).round(3) #renamed for Wells\n",
    "\n",
    "dfbmj3['GWSI_MeasuringPointHeight_m'] = dfbmj3['GWSI_MP_height_ft'].mul(0.3048).round(3)\n",
    "\n",
    "dfbmj3['LandSurfaceAltitude_mASL_NAVD88'] = dfbmj3['GWSI_LandSurfaceAltitude_ftASL_NAVD88'].mul(0.3048).round(3) #renamed for Wells\n",
    "\n",
    "dfbmj3['GWSI_TopOfScreenElevation_ftASL_NAVD88'] = dfbmj3['GWSI_LandSurfaceAltitude_ftASL_NAVD88'] - dfbmj3['GWSI_TopOfScreenDepth_ftBLS']\n",
    "dfbmj3['TopOfScreenElevation_mASL_NAVD88'] = dfbmj3['GWSI_TopOfScreenElevation_ftASL_NAVD88'].mul(0.3048).round(3)\n",
    "\n",
    "dfbmj3['GWSI_BottomOfScreenElevation_ftASL_NAVD88'] = dfbmj3['GWSI_LandSurfaceAltitude_ftASL_NAVD88'] - dfbmj3['GWSI_BottomOfScreenDepth_ftBLS']\n",
    "dfbmj3['BottomOfScreenElevation_mASL_NAVD88'] = dfbmj3['GWSI_BottomOfScreenElevation_ftASL_NAVD88'].mul(0.3048).round(3)\n",
    "\n",
    "dfbmj3['GWSI_MidOfScreenElevation_mASL_NAVD88'] = dfbmj3['TopOfScreenElevation_mASL_NAVD88'] + dfbmj3['BottomOfScreenElevation_mASL_NAVD88']\n",
    "dfbmj3['MidOfScreenElevation_mASL_NAVD88'] = dfbmj3['GWSI_MidOfScreenElevation_mASL_NAVD88'].div(2).round(3)\n",
    "\n",
    "dfbmj3['TotalWellDepth_mBLS'] = dfbmj3['GWSI_TotalWellDepth_ftBLS'].mul(0.3048).round(3) #renamed for Wells\n",
    "\n",
    "dfbmj3['DiameterOfDrillHole_cm'] = dfbmj3['GWSI_DiameterOfDrillHole_inches'].mul(2.54).round(1) #renamed for Wells\n",
    "\n",
    "dfbmj3['WellCasingInnerDiameter_cm'] = dfbmj3['GWSI_WellCasingInnerDiameter_inches'].mul(2.54).round(1) #renamed for Wells\n",
    "\n",
    "dfbmj3['WidthOfOpeningsInOpenInterval_cm'] = dfbmj3['GWSI_WidthOfOpeningsInOpenInterval_inches'].mul(2.54).round(3) #renamed for Wells\n",
    "\n",
    "dfbmj3['GWSI_ScreenLength_ft'] = dfbmj3['GWSI_BottomOfScreenDepth_ftBLS'] - dfbmj3['GWSI_TopOfScreenDepth_ftBLS']\n",
    "dfbmj3['ScreenLength_m'] = dfbmj3['GWSI_ScreenLength_ft'].mul(.3048).round(3) #renamed for Wells\n",
    "\n",
    "dfbmj3['well_MP_height_m'] = dfbmj3['GWSI_MP_height_ft'].mul(.3048).round(3) #renamed for Wells"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tblSites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmilinic\\AppData\\Local\\Temp\\1\\ipykernel_18824\\379343451.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tblSites2['WellSite'] = np.where(tblSites2['LocalSiteName'].isin(tblWells['LocalSiteName']), 1, 0) # inserts 1 if true and 0 if false\n",
      "C:\\Users\\bmilinic\\AppData\\Local\\Temp\\1\\ipykernel_18824\\379343451.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tblSites2['CoreSite'] = np.where(tblSites2['LocalSiteName'].isin(tblCores['LocalSiteName']), 1, 0)\n",
      "C:\\Users\\bmilinic\\AppData\\Local\\Temp\\1\\ipykernel_18824\\379343451.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tblSites2['OtherEquipmentSite'] = np.where(tblSites2['LocalSiteName'].isin(tblOE['LocalSiteName']), 1, 0)\n",
      "C:\\Users\\bmilinic\\AppData\\Local\\Temp\\1\\ipykernel_18824\\379343451.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tblSites2[\"TotalBoring/DrillingDepth_mBLS\"] = tblSites2[\"TotalBoring/DrillingDepth_ftBLS\"].mul(0.3048).round(3)\n"
     ]
    }
   ],
   "source": [
    "# copy and pasted the list of available columns from tblSites2.keys()\n",
    "# select which columns to keep\n",
    "tblSites2 = tblSites[['AgencyCode', 'Wellcon_SiteRecordID', 'DatabasePointType',\n",
    "       'USGS_siteno', 'USGS_StationName', 'LocalSiteName', 'XcoordUTMNAD83_m',\n",
    "       'YcoordUTMNAD83_m', 'LandSurfaceAltitude_ftASL_NAVD88',\n",
    "       'LandSurfaceAltitude_mASL_NAVD88', 'AgencyUse', 'Comments_GWSISite',\n",
    "       'DateOfConstruction', 'Comments_DateOfConstruction', 'VarianceNumber',\n",
    "       'TotalBoring/DrillingDepth_ftBLS', 'VarianceGranted',\n",
    "       'SourceOfDepthData', 'NameOfContractor', 'DrillerName',\n",
    "       'StartingDepthOfHole_ftBLS', 'DiameterOfDrillHole_inches',\n",
    "       'PropertyOwnerName', 'PropertyOwnerAddress',\n",
    "       'HorizontalCoordinateSource', 'SiteRecordNumber', 'NWTPosition_m',\n",
    "       'Loc/MiscCom', 'PlotMaps', 'LogCode', 'SurveyNotes',\n",
    "       'SiteEstablishedForWhom', 'OilSmell', 'SiteVerticalSource',\n",
    "       'SiteActiveStatus', 'XLocal_m_FromArc', 'YLocal_m_FromArc', 'OnNWT',\n",
    "       'Comments_Status', 'ApproxRemovalDate', 'StudySite']]\n",
    "# create indicator columns in tblSites for which sites exist in each of site type tables (wells, cores, other equipment)\n",
    "tblSites2['WellSite'] = np.where(tblSites2['LocalSiteName'].isin(tblWells['LocalSiteName']), 1, 0) # inserts 1 if true and 0 if false\n",
    "tblSites2['CoreSite'] = np.where(tblSites2['LocalSiteName'].isin(tblCores['LocalSiteName']), 1, 0)\n",
    "tblSites2['OtherEquipmentSite'] = np.where(tblSites2['LocalSiteName'].isin(tblOE['LocalSiteName']), 1, 0)\n",
    "\n",
    "# convert from ft to m\n",
    "tblSites2[\"TotalBoring/DrillingDepth_mBLS\"] = tblSites2[\"TotalBoring/DrillingDepth_ftBLS\"].mul(0.3048).round(3)\n",
    "\n",
    "# rename some columns\n",
    "tblSites2 = tblSites2.rename(columns={'OnNWT':'OnNorthWellTransect',\n",
    "                                      'NWTPosition_m':'DistanceFromCenterOfNorthOilBody_m',\n",
    "                                      'LandSurfaceAltitude_mASL_NAVD88':'LandSurfaceElevation_mASL_NAVD88',\n",
    "                                      'Loc/MiscCom':'Comments_Miscellaneous'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tbleSites (local access) with GWSI (retrieved) to update the USGS station names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match up datatypes of the columns that the dfs will be merged on\n",
    "tblSites2['USGS_siteno'] = tblSites2['USGS_siteno'].fillna(0).astype('int64')\n",
    "tblSites3 = pd.merge(tblSites2, dfbmj3[[\n",
    "                                   \"GWSI_USGS_siteno\",\n",
    "                                   \"GWSI_USGS_StationName\",\n",
    "                                   \"GWSI_LandSurfaceAltitude_mASL_NAVD88\",\n",
    "                                   \"GWSI_LandSurfaceAltitude_ftASL_NAVD88\",\n",
    "                                   \"GWSI_DiameterOfDrillHole_inches\",\n",
    "                                   \"GWSI_AgencyUse\",\n",
    "                                   \"GWSI_Comments_GWSISite\",\n",
    "                                   \"GWSI_TotalBoring/DrillingDepth_ftBLS\",\n",
    "                                   \"GWSI_NameOfContractor\" ,\n",
    "                                   \"GWSI_SourceOfDepthData\" ,\n",
    "                                   \"GWSI_StartingDepthOfHole_ftBLS\",\n",
    "                                   \"GWSI_DateOfConstruction\"]],\n",
    "                                   left_on='USGS_siteno', right_on='GWSI_USGS_siteno', how='left')\n",
    "#turn zeros back into NaN\n",
    "tblSites3['USGS_siteno'].replace(0, np.nan, inplace=True) \n",
    "\n",
    "# update USGS station names and date of construction for records with info in GWSI\n",
    "# Combine the station names into one column where GWSI updates the local column IF it is a valid number\n",
    "tblSites3['USGS_StationName'] = tblSites3['GWSI_USGS_StationName'].where(tblSites3['GWSI_USGS_StationName'].notna(), tblSites3['USGS_StationName']) \n",
    "# repeat for date of construction but I have to get the columns in the same date format (YYYYMMDD)\n",
    "tblSites3['DateOfConstruction'] = tblSites3['DateOfConstruction'].dt.strftime('%Y%m%d')\n",
    "tblSites3['DateOfConstruction'] = tblSites3['GWSI_DateOfConstruction'].where(tblSites3['GWSI_DateOfConstruction'].notna(), tblSites3['DateOfConstruction'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEWEST AUTHORITATIVE SOURCES FOR MLR (1/11/2023)\n",
    "tblSites3 = pd.merge(tblSites3, dfmlr, left_on='USGS_siteno', right_on='site_no', how='left')\n",
    "#station name\n",
    "tblSites3['USGS_StationName'] = tblSites3['station_nm'].where(tblSites3['station_nm'].notna(), tblSites3['USGS_StationName'])\n",
    "#landsurfaceelevation\n",
    "tblSites3['alt_va'] = tblSites3['alt_va'].mul(0.3048).round(3) # convert the column from ft to m\n",
    "tblSites3['LandSurfaceElevation_mASL_NAVD88'] = tblSites3['alt_va'].where(tblSites3['alt_va'].notna(), tblSites3['LandSurfaceElevation_mASL_NAVD88'])\n",
    "#dateofconstruction\n",
    "tblSites3['DateOfConstruction'] = tblSites3['construction_dt'].where(tblSites3['construction_dt'].notna(), tblSites3['DateOfConstruction'])\n",
    "#drillingdepth\n",
    "tblSites3['hole_depth_va'] = tblSites3['hole_depth_va'].mul(0.3048).round(3) # convert the column from ft to m\n",
    "tblSites3['TotalBoring/DrillingDepth_mBLS'] = tblSites3['hole_depth_va'].where(tblSites3['hole_depth_va'].notna(), tblSites3['TotalBoring/DrillingDepth_mBLS'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tblWells3['well_depth_va'] = tblWells3['well_depth_va'].mul(0.3048).round(3)\n",
      "tblWells3['TotalWellDepth_mBLS'] = tblWells3['well_depth_va'].where(tblWells3['well_depth_va'].notna(), tblWells3['TotalWellDepth_mBLS'])\n",
      "tblWells3[['USGS_siteno', 'TotalWellDepth_mBLS', 'well_depth_va']].sample(10)\n"
     ]
    }
   ],
   "source": [
    "#automating this process\n",
    "v1 = 'TotalWellDepth_mBLS' # old variable\n",
    "v2 = 'well_depth_va' # new variable\n",
    "t1 = 'tblWells3' # table name\n",
    "\n",
    "\n",
    "print(t1+\"['\"+v2+\"'] = \"+t1+\"['\"+v2+\"'].mul(0.3048).round(3)\")\n",
    "print(t1+\"['\"+v1+\"'] = \"+t1+\"['\"+v2+\"'].where(\"+t1+\"['\"+v2+\"'].notna(), \"+t1+\"['\"+v1+\"'])\")\n",
    "print(t1+\"[['USGS_siteno', '\"+v1+\"', '\"+v2+\"']].sample(10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TotalWellDepth_mBLS'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bmilinic\\OneDrive - DOI\\Documents\\Python\\bemidji\\02_data_convergence.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bmilinic/OneDrive%20-%20DOI/Documents/Python/bemidji/02_data_convergence.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tblSites3[[\u001b[39m'\u001b[39;49m\u001b[39mUSGS_siteno\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mTotalWellDepth_mBLS\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwell_depth_va\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39msample(\u001b[39m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bmilinic\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TotalWellDepth_mBLS'] not in index\""
     ]
    }
   ],
   "source": [
    "tblSites3[['USGS_siteno', 'TotalWellDepth_mBLS', 'well_depth_va']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USGS_siteno</th>\n",
       "      <th>alt_va</th>\n",
       "      <th>LandSurfaceElevation_mASL_NAVD88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>430.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>4.734211e+14</td>\n",
       "      <td>429.838</td>\n",
       "      <td>429.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>4.734271e+14</td>\n",
       "      <td>433.218</td>\n",
       "      <td>433.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>426.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>4.734181e+14</td>\n",
       "      <td>430.743</td>\n",
       "      <td>430.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>4.734261e+14</td>\n",
       "      <td>430.655</td>\n",
       "      <td>430.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>430.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       USGS_siteno   alt_va  LandSurfaceElevation_mASL_NAVD88\n",
       "337            NaN      NaN                           430.557\n",
       "376            NaN      NaN                           432.949\n",
       "1127  4.734211e+14  429.838                           429.839\n",
       "923   4.734271e+14  433.218                           433.219\n",
       "168            NaN      NaN                           426.071\n",
       "955   4.734181e+14  430.743                           430.742\n",
       "586            NaN      NaN                           432.820\n",
       "908   4.734261e+14  430.655                           430.655\n",
       "57             NaN      NaN                           433.337\n",
       "1354           NaN      NaN                           430.167\n",
       "523            NaN      NaN                           433.345"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my check to see if alt_va and LandSurfaceElvation were similar when both values existed\n",
    "tblSites3[['USGS_siteno', 'alt_va', 'LandSurfaceElevation_mASL_NAVD88']].sample(11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tblWells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which columns to keep\n",
    "tblWells2 = tblWells[['WellEntryRecordNumber', 'LocalSiteName', 'LocalSiteWellSubName',\n",
    "       'GWSISiteType', 'MNUniqueNmbr', 'GWSIUseOfSite', 'GWSIAquiferType',\n",
    "       'GWSIPrimaryAquifer', 'GWSINationalAquifer', 'TypeOfBackFill',\n",
    "       'NumberBagsOfCleanSand', 'BentoniteUsed', 'TypeOfBentonite',\n",
    "       'CoreTakenBeforeWellInstallation', 'TailPipeLength_ft',\n",
    "       'TailPipeLengthRemarks', 'ProtectionPipeInstalled',\n",
    "       'ProtectionPipeMaterial', 'DiameterOfProtectionPipe',\n",
    "       'ProtectionPipeLength_ft', 'LengthBetweenProtectionPipeAndMP',\n",
    "       'CementPadInstalled', 'DrilledForWhom', 'DrillersFieldComments',\n",
    "       'TotalWellDepth_ftBLS', 'StickupLength_ft', 'StickupSource',\n",
    "       'WellCasingInnerDiameter_inches', 'CasingMaterial',\n",
    "       'SourceOfConstructionData', 'MethodOfConstruction', 'TypeOfFinish',\n",
    "       'NumberBagsOfGrout', 'TypeOfSeal', 'WellGrouted', 'DepthofSeal_ftBLS',\n",
    "       'StartOfSeal_ftBLS', 'MethodOfDevelopment', 'HoursOfDevelopment',\n",
    "       'SpecialTreatmentForDevelopment', 'TopOfScreenDepth_ftBLS',\n",
    "       'MidOfScreenDepth_ftBLS', 'BottomOfScreenDepth_ftBLS',\n",
    "       'Comments_TopOfScreenDepth', 'Comments_MidScreenDepth',\n",
    "       'Comments_BottomOfScreenDepth', 'ScreenLength_ft',\n",
    "       'ScreenLengthRemarks', 'ScreenInnerDiameter_inches',\n",
    "       'ScreenMaterialType', 'TypeOfOpenInterval',\n",
    "       'WidthOfOpeningsInOpenInterval_inches', 'WellOwnerName',\n",
    "       'WellOwnerAddress', 'ScreenMake', 'LicenseeBusinessName', 'LicNum',\n",
    "       'CertifiedRepresentative', 'CertifiedRepNo', 'DateSignedAndCertified',\n",
    "       'AltitudeOfMeasuringPoint_ftASL_NAVD88',\n",
    "       'AltitudeOfMeasuringPoint_mASL_NAVD88', 'MeasuringPointAltitudeRemarks',\n",
    "       'LandSurfaceAltitude_ftASL_NAVD88', 'Pre2010_CasMat', 'LocalUseCode',\n",
    "       'WellMPVerticalSource', 'Wellcon_SiteRecordID', 'WellPurpose',\n",
    "       'WellProjectID', 'WaterTableWell', 'SouthPoolWell', 'QuarterlyWLSite',\n",
    "       'TransducerSite', 'DifficultToPump', 'DifficultToPump_Comments']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tblWells to add all columns needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE MASTER SITE LIST\n",
    "mastersitelist = pd.merge (tblSites3, tblWells2, on='LocalSiteName', how='left')\n",
    "mastersitelist = pd.merge(mastersitelist, dfbmj3, left_on='USGS_siteno', right_on='GWSI_USGS_siteno', how='left')\n",
    "mastersitelist = mastersitelist[[\"LocalSiteName\",\n",
    "                            \"StudySite\",\n",
    "                            \"AgencyCode\",\n",
    "                            \"USGS_siteno\",\n",
    "                            \"USGS_StationName\",\n",
    "                            \"XcoordUTMNAD83_m\",\n",
    "                            \"YcoordUTMNAD83_m\",\n",
    "                            \"LandSurfaceElevation_mASL_NAVD88\",\n",
    "                            \"OnNorthWellTransect\",\n",
    "                            \"DistanceFromCenterOfNorthOilBody_m\",\n",
    "                            \"WellSite\",\n",
    "                            \"CoreSite\",\n",
    "                            \"OtherEquipmentSite\",\n",
    "                            \"TopOfScreenElevation_mASL_NAVD88\",\n",
    "                            \"BottomOfScreenElevation_mASL_NAVD88\",\n",
    "                            \"MidOfScreenElevation_mASL_NAVD88\",\n",
    "                            \"DateOfConstruction\",\n",
    "                            \"Comments_DateOfConstruction\",\n",
    "                            \"SiteActiveStatus\",\n",
    "                            \"Comments_Status\",\n",
    "                            \"ApproxRemovalDate\"]]\n",
    "\n",
    "# format date\n",
    "mastersitelist['LocalSiteName'] = 'x' + mastersitelist['LocalSiteName'].astype(str)\n",
    "mastersitelist['USGS_siteno'] = 'x' + mastersitelist['USGS_siteno'].astype(str)\n",
    "\n",
    "# make nan values uniform\n",
    "mastersitelist['USGS_siteno'] = mastersitelist['USGS_siteno'].replace('xnan', np.nan)\n",
    "null_cells = mastersitelist.isnull()\n",
    "mastersitelist = mastersitelist.astype(str).mask(null_cells, np.NaN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tblOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmilinic\\AppData\\Local\\Temp\\1\\ipykernel_18824\\3637828156.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tblOE2[\"OtherEquipStickupLength_m\"] = tblOE2[\"OtherEquipStickupLength_ft\"].mul(0.3048).round(3)\n"
     ]
    }
   ],
   "source": [
    "tblOE2 = tblOE[[\"LocalSiteName\",\n",
    "                \"LocalUseCode\",\n",
    "                \"OtherEquipStickupLength_ft\",\n",
    "                \"OtherEquipmentPurpose\",\n",
    "                \"Comments_Equipment\",\n",
    "                \"Comments\"]]\n",
    "\n",
    "tblOE2[\"OtherEquipStickupLength_m\"] = tblOE2[\"OtherEquipStickupLength_ft\"].mul(0.3048).round(3)\n",
    "tblOE2 = tblOE2.rename(columns={'OtherEquipStickupLength_m':'OtherEquip_MP_height_m'})\n",
    "\n",
    "tblOE2 = pd.merge(tblOE2, tblSites3[[\"LocalSiteName\",\n",
    "                                   \"StudySite\",\n",
    "                                   \"USGS_siteno\",\n",
    "                                   \"USGS_StationName\",\n",
    "                                   \"XcoordUTMNAD83_m\",\n",
    "                                   \"YcoordUTMNAD83_m\",\n",
    "                                   \"OnNorthWellTransect\",\n",
    "                                   \"DistanceFromCenterOfNorthOilBody_m\",\n",
    "                                   \"LandSurfaceElevation_mASL_NAVD88\",\n",
    "                                   \"DateOfConstruction\",\n",
    "                                   \"Comments_DateOfConstruction\",\n",
    "                                   \"NameOfContractor\",\n",
    "                                   \"DrillerName\",\n",
    "                                   \"Comments_Miscellaneous\"]], how='left')\n",
    "tblOE2 = pd.merge(tblOE2, tblcd_LocalUseCode[['LocalUseCode','Comments_UseCode']])\n",
    "\n",
    "tblOE2 = tblOE2[[\"LocalSiteName\",\n",
    "                 \"StudySite\",\n",
    "                 \"LocalUseCode\",\n",
    "                 \"Comments_UseCode\",\n",
    "                 \"USGS_siteno\",\n",
    "                 \"USGS_StationName\",\n",
    "                 \"XcoordUTMNAD83_m\",\n",
    "                 \"YcoordUTMNAD83_m\",\n",
    "                 \"OnNorthWellTransect\",\n",
    "                 \"DistanceFromCenterOfNorthOilBody_m\",\n",
    "                 \"LandSurfaceElevation_mASL_NAVD88\",\n",
    "                 \"OtherEquip_MP_height_m\",\n",
    "                 \"DateOfConstruction\",\n",
    "                 \"Comments_DateOfConstruction\",\n",
    "                 \"NameOfContractor\",\n",
    "                 \"DrillerName\",\n",
    "                 \"OtherEquipmentPurpose\",\n",
    "                 \"Comments_Equipment\",\n",
    "                 \"Comments\",\n",
    "                 \"Comments_Miscellaneous\"]]\n",
    "tblOE2['LocalSiteName'] = 'x' + tblOE2['LocalSiteName'].astype(str)\n",
    "tblOE2['USGS_siteno'] = 'x' + tblOE2['USGS_siteno'].astype(str)\n",
    "tblOE2['USGS_siteno'] = tblOE2['USGS_siteno'].replace('xnan', np.nan)\n",
    "null_cells = tblOE2.isnull()\n",
    "tblOE2 = tblOE2.astype(str).mask(null_cells, np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tblCores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "tblCores2 = tblCores[['CoreEntryRecordNumber', 'LocalSiteName', 'LocalSiteCoreSubName',\n",
    "       'CoreLocationNear', 'DepthDrilledBeforeCoring_ftBLS',\n",
    "       'CoringBegan_ftBLS', 'CoringEnded_ftBLS', 'CoreBarrelType',\n",
    "       'TotalCoreLengthPounded_ft', 'CoreDrivingEquipment', 'OilSmell',\n",
    "       'C02Used', 'TakeC02', 'CoreRecoveryLength_ft', 'MethaneBubblesPresent',\n",
    "       'SubsurfaceCoreZone', 'PostCoreEquipmentInstallation', 'MultipleCores',\n",
    "       'FreeProductOilPresentInCore', 'DrillersFieldComments',\n",
    "       'TypeOfBackFill', 'NumberBagsOfBentonite', 'BentoniteUsed',\n",
    "       'GWSIMethodOfConstruction', 'TypeOfSeal', 'DepthofSeal_ftBLS',\n",
    "       'StartOfSeal_ftBLS', 'SourceOfConstructionData', 'CoreStickupSource',\n",
    "       'CoreStickupLength_ft', 'TypeOfBentonite', 'NumberOfBagsCleanSand',\n",
    "       'CoreAltitudeOfMeasuringPoint_ftASL_NAVD88',\n",
    "       'CoreAltitudeOfMeasuringPoint_mASL_NAVD88',\n",
    "       'CoreMeasuringPointAltitudeRemarks', 'CoreMPVerticalSource',\n",
    "       'LocalUseCode', 'Wellcon_SiteRecordID', 'CorePurposePlannedAnalyses',\n",
    "       'CoreProjectID', 'CementPadInstalled', 'MarkedWithCorePlate',]]  \n",
    "\n",
    "#Calculations loop AND renaming\n",
    "vars_ft = ['CoreStickupLength_ft',\n",
    "           'CoringBegan_ftBLS',\n",
    "           'CoringEnded_ftBLS',\n",
    "           'CoreRecoveryLength_ft',\n",
    "           'TotalCoreLengthPounded_ft']\n",
    "vars_m = [i.replace('ft', 'm') for i in vars_ft]\n",
    "for var_ft, var_m in zip(vars_ft, vars_m):\n",
    "        tblCores2[var_m] = tblCores2[var_ft].mul(0.3048).round(3)\n",
    "\n",
    "tblCores2 = tblCores2.rename(columns={\n",
    "                                'CoreStickupLength_m':'Core_MP_height_m',\n",
    "                                'TotalCoreLengthPounded_m':'CoreLengthPounded_m'})\n",
    "\n",
    "#Merging\n",
    "tblCores2 = pd.merge(tblCores2, tblSites3[[\"LocalSiteName\",\n",
    "                                     \"StudySite\",\n",
    "                                     \"USGS_siteno\",\n",
    "                                     \"USGS_StationName\",\n",
    "                                     \"XcoordUTMNAD83_m\",\n",
    "                                     \"YcoordUTMNAD83_m\",\n",
    "                                     \"OnNorthWellTransect\",\n",
    "                                     \"DistanceFromCenterOfNorthOilBody_m\",\n",
    "                                     \"LandSurfaceElevation_mASL_NAVD88\",\n",
    "                                     \"TotalBoring/DrillingDepth_mBLS\", \n",
    "                                     \"DateOfConstruction\",\n",
    "                                     \"Comments_DateOfConstruction\",\n",
    "                                     \"TotalBoring/DrillingDepth_ftBLS\", \n",
    "                                     \"NameOfContractor\",\n",
    "                                     \"DrillerName\",\n",
    "                                     \"Comments_Miscellaneous\"]], how='left')\n",
    "tblCores2 = pd.merge(tblCores2, tblcd_LocalUseCode[['LocalUseCode','Comments_UseCode']])\n",
    "\n",
    "#New calculaton after merge\n",
    "tblCores2['TopOfCoreElevation_mASL_NAVD88'] = tblCores2['LandSurfaceElevation_mASL_NAVD88'] - tblCores2['CoringBegan_mBLS']\n",
    "\n",
    "#rearange to put in order of data release\n",
    "tblCores2 = tblCores2[[\"LocalSiteName\",\n",
    "                       \"StudySite\",\n",
    "                       \"LocalUseCode\",\n",
    "                       \"Comments_UseCode\",\n",
    "                       \"USGS_siteno\",\n",
    "                       \"USGS_StationName\",\n",
    "                       \"LocalSiteCoreSubName\",\n",
    "                       \"XcoordUTMNAD83_m\",\n",
    "                       \"YcoordUTMNAD83_m\",\n",
    "                       \"OnNorthWellTransect\",\n",
    "                       \"DistanceFromCenterOfNorthOilBody_m\",\n",
    "                       \"LandSurfaceElevation_mASL_NAVD88\",\n",
    "                       \"Core_MP_height_m\",\n",
    "                       \"DateOfConstruction\",\n",
    "                       \"Comments_DateOfConstruction\",\n",
    "                       \"TotalBoring/DrillingDepth_mBLS\",\n",
    "                       \"NameOfContractor\",\n",
    "                       \"DrillerName\",\n",
    "                       \"CoringBegan_mBLS\",\n",
    "                       \"CoringEnded_mBLS\",\n",
    "                       \"CoreRecoveryLength_m\",\n",
    "                       \"TopOfCoreElevation_mASL_NAVD88\",\n",
    "                       \"CoreLengthPounded_m\",\n",
    "                       \"CoreBarrelType\",\n",
    "                       \"SubsurfaceCoreZone\",\n",
    "                       \"FreeProductOilPresentInCore\",\n",
    "                       \"DrillersFieldComments\",\n",
    "                       \"Comments_Miscellaneous\"]]       \n",
    "\n",
    "#Format columns and male nan values uniform\n",
    "tblCores2['LocalSiteName'] = 'x' + tblCores2['LocalSiteName'].astype(str)\n",
    "tblCores2['USGS_siteno'] = 'x' + tblCores2['USGS_siteno'].astype(str)\n",
    "tblCores2['USGS_siteno'] = tblCores2['USGS_siteno'].replace('xnan', np.nan)\n",
    "null_cells = tblCores2.isnull()\n",
    "tblCores2 = tblCores2.astype(str).mask(null_cells, np.NaN)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tblWells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['agency_cd', 'alt_acy_va', 'alt_datum_cd', 'alt_meth_cd', 'alt_va',\n",
       "       'aqfr_cd', 'aqfr_type_cd', 'basin_cd', 'construction_dt',\n",
       "       'contrib_drain_area_va', 'coord_acy_cd', 'coord_datum_cd',\n",
       "       'coord_meth_cd', 'country_cd', 'county_cd', 'dec_coord_datum_cd',\n",
       "       'dec_lat_va', 'dec_long_va', 'depth_src_cd', 'district_cd',\n",
       "       'drain_area_va', 'gw_file_cd', 'hole_depth_va', 'huc_cd',\n",
       "       'instruments_cd', 'inventory_dt', 'land_net_ds', 'lat_va',\n",
       "       'local_time_fg', 'long_va', 'map_nm', 'map_scale_fc', 'nat_aqfr_cd',\n",
       "       'project_no', 'reliability_cd', 'site_no', 'site_tp_cd', 'state_cd',\n",
       "       'station_nm', 'topo_cd', 'tz_cd', 'well_depth_va'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PRINT OUT DF KEYS IN ABC ORDER\n",
    "dfmlr.reindex(sorted(dfmlr.columns), axis=1).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AgencyCode', 'AgencyUse', 'AltitudeOfMeasuringPoint_ftASL_NAVD88',\n",
       "       'AltitudeOfMeasuringPoint_mASL_NAVD88', 'AppliedByUser', 'AppliedTime',\n",
       "       'ApproxRemovalDate', 'BentoniteUsed', 'BottomOfScreenDepth_ftBLS',\n",
       "       'BottomOfScreenElevation_mASL_NAVD88',\n",
       "       ...\n",
       "       'reliability_cd', 'site', 'site_no', 'site_tp_cd', 'state_cd',\n",
       "       'station_nm', 'topo_cd', 'tz_cd', 'well_MP_height_m', 'well_depth_va'],\n",
       "      dtype='object', length=274)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PRINT OUT DF KEYS IN ABC ORDER\n",
    "tblWells3.reindex(sorted(tblWells3.columns), axis=1).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since already created, start with the merge\n",
    "tblWells3 = pd.merge(tblWells2, tblSites3,  on='LocalSiteName', how='left') #tblSites3 here already has dfmlr in it!\n",
    "tblWells3 = pd.merge(tblWells3, dfbmj3, left_on='USGS_siteno', right_on='GWSI_USGS_siteno', how='left')\n",
    "\n",
    "# add tblcd info\n",
    "tblWells3 = pd.merge(tblWells3, tblcd_OpeningType[[\"TypeOfOpenInterval\", \"comments_OpeningType\"]], left_on='GWSI_TypeOfOpenInterval', right_on='TypeOfOpenInterval', how='left')\n",
    "tblWells3 = pd.merge(tblWells3, tblcd_LocalUseCode[[\"LocalUseCode\", \"Comments_UseCode\"]], how='left')\n",
    "tblWells3 = pd.merge(tblWells3, tblcd_CasingMaterial[[\"CasingMaterial\", \"Comments_CasingMaterial\"]], left_on='GWSI_CasingMaterial', right_on='CasingMaterial', how='left')\n",
    "tblWells3 = pd.merge(tblWells3, tblcd_ScreenMaterial[[\"ScreenMaterial\", \"Comments_ScreenMaterial\"]], left_on='GWSI_ScreenMaterialType', right_on='ScreenMaterial', how='left')\n",
    "\n",
    "# rename tblcd info\n",
    "tblWells3 = tblWells3.rename(columns={\"comments_OpeningType\":'OpeningTypeDescription'})\n",
    "tblWells3 = tblWells3.rename(columns={\"Comments_CasingMaterial\":'CasingMaterialDescription'})\n",
    "tblWells3 = tblWells3.rename(columns={\"Comments_ScreenMaterial\":'ScreenMaterialDescription'})\n",
    "\n",
    "# NEWEST AUTHORITATIVE SOURCES (1/11/2023) for MLR (already in tblWells3 since its already in tblSites3)\n",
    "# well depth\n",
    "tblWells3['well_depth_va'] = tblWells3['well_depth_va'].mul(0.3048).round(3)\n",
    "tblWells3['TotalWellDepth_mBLS'] = tblWells3['well_depth_va'].where(tblWells3['well_depth_va'].notna(), tblWells3['TotalWellDepth_mBLS'])\n",
    "#AQUARIUS\n",
    "tblWells3 = pd.merge(tblWells3, dfaq, left_on='USGS_siteno', right_on='site', how='left')\n",
    "#MP height\n",
    "tblWells3['Elevation'] = tblWells3['Elevation'].mul(0.3048).round(3)\n",
    "tblWells3['well_MP_height_m'] = tblWells3['Elevation'].where(tblWells3['Elevation'].notna(), tblWells3['well_MP_height_m'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfConstruction</th>\n",
       "      <th>ApproxRemovalDate</th>\n",
       "      <th>ValidFrom</th>\n",
       "      <th>DecommissionedDate</th>\n",
       "      <th>GWSI_MP_BeginDate</th>\n",
       "      <th>GWSI_MP_EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>19840701.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1984-07-02T00:00:00.0000000-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19840702.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>20040721.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20040721.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>20050615.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0001-01-01T00:00:00.0000000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20050616.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>19880607.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0001-01-01T00:00:00.0000000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19880608.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>19970620.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1997-06-20T00:00:00.0000000-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19970620.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>20170628.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170628.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>19830701.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1983-07-01T00:00:00.0000000-06:00</td>\n",
       "      <td>1983-07-02T00:00:00.0000000-06:00</td>\n",
       "      <td>19830702.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>19970620.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1997-06-20T00:00:00.0000000-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19970620.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DateOfConstruction ApproxRemovalDate                          ValidFrom  \\\n",
       "269         19840701.0              None  1984-07-02T00:00:00.0000000-06:00   \n",
       "545         20040721.0              None                                NaN   \n",
       "595         20050615.0              None  0001-01-01T00:00:00.0000000+00:00   \n",
       "308         19880607.0              None  0001-01-01T00:00:00.0000000+00:00   \n",
       "95          19970620.0              None  1997-06-20T00:00:00.0000000-06:00   \n",
       "616                NaN              None                                NaN   \n",
       "740                NaN              None                                NaN   \n",
       "844         20170628.0              None                                NaN   \n",
       "202         19830701.0              None  1983-07-01T00:00:00.0000000-06:00   \n",
       "91          19970620.0              None  1997-06-20T00:00:00.0000000-06:00   \n",
       "\n",
       "                    DecommissionedDate  GWSI_MP_BeginDate  GWSI_MP_EndDate  \n",
       "269                                NaN         19840702.0              NaN  \n",
       "545                                NaN         20040721.0              NaN  \n",
       "595                                NaN         20050616.0              NaN  \n",
       "308                                NaN         19880608.0              NaN  \n",
       "95                                 NaN         19970620.0              NaN  \n",
       "616                                NaN                NaN              NaN  \n",
       "740                                NaN                NaN              NaN  \n",
       "844                                NaN         20170628.0              NaN  \n",
       "202  1983-07-02T00:00:00.0000000-06:00         19830702.0              NaN  \n",
       "91                                 NaN         19970620.0              NaN  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tblWells3[['DateOfConstruction','ApproxRemovalDate','ValidFrom','DecommissionedDate', 'GWSI_MP_BeginDate', 'GWSI_MP_EndDate']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tblWells3['Elevation'] = tblWells3['Elevation'].mul(0.3048).round(3)\n",
      "tblWells3['well_MP_height_m'] = tblWells3['Elevation'].where(tblWells3['Elevation'].notna(), tblWells3['well_MP_height_m'])\n",
      "tblWells3[['USGS_siteno', 'well_MP_height_m', 'Elevation']].sample(10)\n"
     ]
    }
   ],
   "source": [
    "#automating this process\n",
    "v1 = 'well_MP_height_m' # old variable\n",
    "v2 = 'Elevation' # new variable\n",
    "t1 = 'tblWells3' # table name\n",
    "\n",
    "\n",
    "print(t1+\"['\"+v2+\"'] = \"+t1+\"['\"+v2+\"'].mul(0.3048).round(3)\")\n",
    "print(t1+\"['\"+v1+\"'] = \"+t1+\"['\"+v2+\"'].where(\"+t1+\"['\"+v2+\"'].notna(), \"+t1+\"['\"+v1+\"'])\")\n",
    "print(t1+\"[['USGS_siteno', '\"+v1+\"', '\"+v2+\"']].sample(10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data release\n",
    "# select a subset of data\n",
    "tblWells3 = tblWells3[[\"LocalSiteName\",\n",
    "                       \"StudySite\",\n",
    "                       \"LocalUseCode\",\n",
    "                       \"Comments_UseCode\",\n",
    "                       \"USGS_siteno\",\n",
    "                       \"USGS_StationName\",\n",
    "                       \"XcoordUTMNAD83_m\",\n",
    "                       \"YcoordUTMNAD83_m\",\n",
    "                       \"OnNorthWellTransect\",\n",
    "                       \"DistanceFromCenterOfNorthOilBody_m\",\n",
    "                       \"MeasuringPointElevation_mASL_NAVD88\", \n",
    "                       \"well_MP_height_m\",\n",
    "                       \"LandSurfaceAltitude_mASL_NAVD88\",\n",
    "                       \"TopOfScreenElevation_mASL_NAVD88\",\n",
    "                       \"BottomOfScreenElevation_mASL_NAVD88\",\n",
    "                       \"ScreenLength_m\",\n",
    "                       \"MidOfScreenElevation_mASL_NAVD88\",\n",
    "                       \"TotalWellDepth_mBLS\",\n",
    "                       \"TotalBoring/DrillingDepth_mBLS\",\n",
    "                       \"DiameterOfDrillHole_cm\",\n",
    "                       \"WellCasingInnerDiameter_cm\",\n",
    "                       \"OpeningTypeDescription\",\n",
    "                       \"WidthOfOpeningsInOpenInterval_cm\",\n",
    "                       \"CasingMaterialDescription\",\n",
    "                       \"ScreenMaterialDescription\",\n",
    "                       \"DateOfConstruction\",\n",
    "                       \"Comments_DateOfConstruction\",\n",
    "                       \"NameOfContractor\",\n",
    "                       \"DrillerName\",\n",
    "                       \"Comments_Miscellaneous\",\n",
    "                       \"SiteActiveStatus\",\n",
    "                       \"Comments_Status\",\n",
    "                       \"ApproxRemovalDate\"]]  \n",
    "\n",
    "# formatting columns\n",
    "tblWells3['LocalSiteName'] = 'x' + tblWells3['LocalSiteName'].astype(str)\n",
    "tblWells3['USGS_siteno'] = 'x' + tblWells3['USGS_siteno'].astype(str)\n",
    "#Make nan values uniform\n",
    "tblWells3['USGS_siteno'] = tblWells3['USGS_siteno'].replace('xnan', np.nan)\n",
    "null_cells = tblWells3.isnull()\n",
    "tblWells3 = tblWells3.astype(str).mask(null_cells, np.NaN)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bmj_rmk data release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrmk2 = dfrmk[['GWSI_AgencyCode', 'GWSI_USGS_siteno', 'GWSI_GWSI_RMK',\n",
    "       'GWSI_GWSI_RMK_Date', 'GWSI_GWSI_RMK_SequenceNo']]\n",
    "\n",
    "# make columns the same datatype of interger\n",
    "tblSites['USGS_siteno'] = tblSites['USGS_siteno'].fillna(0).astype('int64')\n",
    "# dfrmk2's is already an interger\n",
    "dfrmk2 = pd.merge(dfrmk2, tblSites[['USGS_siteno', 'LocalSiteName']], left_on= \"GWSI_USGS_siteno\", right_on= 'USGS_siteno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmilinic\\AppData\\Local\\Temp\\1\\ipykernel_26708\\3278186708.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfrmk3['GWSI_USGS_siteno'] = 'x' + dfrmk3['GWSI_USGS_siteno'].astype(str)\n",
      "C:\\Users\\bmilinic\\AppData\\Local\\Temp\\1\\ipykernel_26708\\3278186708.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfrmk3['LocalSiteName'] = 'x' + dfrmk3['LocalSiteName'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# organize for data release\n",
    "dfrmk3 = dfrmk2[['GWSI_AgencyCode',\n",
    "                 'GWSI_USGS_siteno',\n",
    "                 'LocalSiteName',\n",
    "                 'GWSI_GWSI_RMK',\n",
    "                 'GWSI_GWSI_RMK_Date',\n",
    "                 'GWSI_GWSI_RMK_SequenceNo']]\n",
    "# format numbers with 'x'\n",
    "dfrmk3['GWSI_USGS_siteno'] = 'x' + dfrmk3['GWSI_USGS_siteno'].astype(str)\n",
    "dfrmk3['LocalSiteName'] = 'x' + dfrmk3['LocalSiteName'].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Every Figure in a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable with today's date\n",
    "date = datetime.today().strftime('%Y%m%d') \n",
    "# create variable for new folder/directory\n",
    "dir = \"data_outputs/\"+date+\"_datarelease\" # new directory location and name\n",
    "# create the directory unless it already exists...then skip\n",
    "try:\n",
    "    os.mkdir(dir)\n",
    "except:\n",
    "    pass\n",
    "# save all the files there \n",
    "mastersitelist.to_csv(dir+\"/DataRelease_MasterSiteList.csv\", index=False)\n",
    "tblOE2.to_csv(dir+\"/DataRelease_OtherEquipmentInformation.csv\", index=False)\n",
    "tblCores2.to_csv(dir+\"/DataRelease_CoreInformation.csv\", index=False)\n",
    "tblWells3.to_csv(dir+\"/DataRelease_WellConstructionInformation.csv\", index=False)\n",
    "dfrmk3.to_csv(dir+\"/DataRelease_rmk3.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the caveat that keeps popping up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GWSI_AgencyCode</th>\n",
       "      <th>GWSI_USGS_siteno</th>\n",
       "      <th>GWSI_GWSI_RMK</th>\n",
       "      <th>GWSI_GWSI_RMK_Date</th>\n",
       "      <th>GWSI_GWSI_RMK_SequenceNo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473429095051006</td>\n",
       "      <td>This well was re-surveyed on 27 June 2019 by J...</td>\n",
       "      <td>20190730.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473429095051006</td>\n",
       "      <td>Digital levels were then ran from the temporar...</td>\n",
       "      <td>20190730.000</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473429095051006</td>\n",
       "      <td>This well casing is constructed of stainless s...</td>\n",
       "      <td>20190730.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473424095052912</td>\n",
       "      <td>This is port \"01\" for vadose zone vapor/gas sa...</td>\n",
       "      <td>20200206.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473424095052906</td>\n",
       "      <td>This is port \"01\" for vadose zone vapor/gas sa...</td>\n",
       "      <td>20200206.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473419095052503</td>\n",
       "      <td>This is the location of a wetland staff gage f...</td>\n",
       "      <td>20190730.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473419095052304</td>\n",
       "      <td>This is port \"01\" for vadose zone vapor/gas sa...</td>\n",
       "      <td>20200206.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473425095051601</td>\n",
       "      <td>This is a monitoring well used for the Bemidji...</td>\n",
       "      <td>20170726.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473423095051501</td>\n",
       "      <td>This monitoring well used for the Bemidji Toxi...</td>\n",
       "      <td>20170726.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>USGS</td>\n",
       "      <td>473424095053001</td>\n",
       "      <td>This is port \"01\" for vadose zone vapor/gas sa...</td>\n",
       "      <td>20200206.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GWSI_AgencyCode  GWSI_USGS_siteno  \\\n",
       "0              USGS   473429095051006   \n",
       "1              USGS   473429095051006   \n",
       "2              USGS   473429095051006   \n",
       "3              USGS   473424095052912   \n",
       "4              USGS   473424095052906   \n",
       "..              ...               ...   \n",
       "628            USGS   473419095052503   \n",
       "629            USGS   473419095052304   \n",
       "630            USGS   473425095051601   \n",
       "631            USGS   473423095051501   \n",
       "632            USGS   473424095053001   \n",
       "\n",
       "                                         GWSI_GWSI_RMK  GWSI_GWSI_RMK_Date  \\\n",
       "0    This well was re-surveyed on 27 June 2019 by J...        20190730.000   \n",
       "1    Digital levels were then ran from the temporar...        20190730.000   \n",
       "2    This well casing is constructed of stainless s...        20190730.000   \n",
       "3    This is port \"01\" for vadose zone vapor/gas sa...        20200206.000   \n",
       "4    This is port \"01\" for vadose zone vapor/gas sa...        20200206.000   \n",
       "..                                                 ...                 ...   \n",
       "628  This is the location of a wetland staff gage f...        20190730.000   \n",
       "629  This is port \"01\" for vadose zone vapor/gas sa...        20200206.000   \n",
       "630  This is a monitoring well used for the Bemidji...        20170726.000   \n",
       "631  This monitoring well used for the Bemidji Toxi...        20170726.000   \n",
       "632  This is port \"01\" for vadose zone vapor/gas sa...        20200206.000   \n",
       "\n",
       "     GWSI_GWSI_RMK_SequenceNo  \n",
       "0                       1.000  \n",
       "1                       2.000  \n",
       "2                       3.000  \n",
       "3                       1.000  \n",
       "4                       1.000  \n",
       "..                        ...  \n",
       "628                     1.000  \n",
       "629                     1.000  \n",
       "630                     1.000  \n",
       "631                     1.000  \n",
       "632                     1.000  \n",
       "\n",
       "[633 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfrmk2 = dfrmk[['GWSI_AgencyCode', \n",
    "                'GWSI_USGS_siteno', \n",
    "                'GWSI_GWSI_RMK',\n",
    "                'GWSI_GWSI_RMK_Date', \n",
    "                'GWSI_GWSI_RMK_SequenceNo']]\n",
    "\n",
    "#would translate into\n",
    "\n",
    "dfrmk2 = dfrmk.loc[:, ['GWSI_AgencyCode', \n",
    "                      'GWSI_USGS_siteno', \n",
    "                      'GWSI_GWSI_RMK',\n",
    "                      'GWSI_GWSI_RMK_Date', \n",
    "                      'GWSI_GWSI_RMK_SequenceNo']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88f0d5da0f5c51017bf5fa1411746da694b8be09d55cffcd352725c954b24f48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
